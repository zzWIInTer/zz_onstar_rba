{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Regularized Regression.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Regularized Regression"],"metadata":{"id":"CHymZNg1L3Ur"}},{"cell_type":"code","source":["###########################################################################\n","#\n","#  Copyright 2021 Google Inc.\n","#\n","#  Licensed under the Apache License, Version 2.0 (the \"License\");\n","#  you may not use this file except in compliance with the License.\n","#  You may obtain a copy of the License at\n","#\n","#      https://www.apache.org/licenses/LICENSE-2.0\n","#\n","#  Unless required by applicable law or agreed to in writing, software\n","#  distributed under the License is distributed on an \"AS IS\" BASIS,\n","#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","#  See the License for the specific language governing permissions and\n","#  limitations under the License.\n","#\n","# This solution, including any related sample code or data, is made available \n","# on an “as is,” “as available,” and “with all faults” basis, solely for \n","# illustrative purposes, and without warranty or representation of any kind. \n","# This solution is experimental, unsupported and provided solely for your \n","# convenience. Your use of it is subject to your agreements with Google, as \n","# applicable, and may constitute a beta feature as defined under those \n","# agreements.  To the extent that you make any data available to Google in \n","# connection with your use of the solution, you represent and warrant that you \n","# have all necessary and appropriate rights, consents and permissions to permit \n","# Google to use and process that data.  By using any portion of this solution, \n","# you acknowledge, assume and accept all risks, known and unknown, associated \n","# with its usage, including with respect to your deployment of any portion of \n","# this solution in your systems, or usage in connection with your business, \n","# if at all.\n","###########################################################################"],"metadata":{"id":"z0rsw8_TL7R_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l19lClJob3IR"},"source":["## 0) Dependencies"]},{"cell_type":"code","source":["################################################################################\n","######################### CHANGE BQ PROJECT NAME BELOW #########################\n","################################################################################\n","\n","project_name = '' #add proj name and dataset"],"metadata":{"id":"bhKxsbosL_nM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculating Relative Importance\n","!pip install relativeImp\n","!pip install shap"],"metadata":{"id":"5rxPwul81buP"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4aupXJjFcHkq"},"source":["# Google credentials authentication libraries\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","# data processing libraries\n","import numpy as np\n","from numpy.core.numeric import NaN\n","import pandas as pd\n","import pandas_gbq\n","import datetime\n","\n","# modeling and metrics\n","from scipy.optimize import least_squares\n","from statsmodels.tools.tools import add_constant\n","import statsmodels.api as sm\n","from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut, KFold, LeavePOut\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","from statsmodels.stats.stattools import durbin_watson\n","from sklearn.model_selection import TimeSeriesSplit\n","\n","# Visualization\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","\n","# Calculating Relative Importance\n","from relativeImp import relativeImp\n","import shap\n","\n","# BigQuery Magics\n","'''\n","BigQuery magics are used to run BigQuery SQL queries in a python environment.\n","These queries can also be run in the BigQuery UI\n","'''\n","\n","from google.cloud import bigquery\n","from google.cloud.bigquery import magics\n","\n","\n","from google.colab import files\n","\n","\n","magics.context.project = project_name  #update your project name \n","\n","client = bigquery.Client(project=magics.context.project)\n","%load_ext google.cloud.bigquery\n","bigquery.USE_LEGACY_SQL = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZEieYk1j9w3h"},"source":["## 1) Import dataset"]},{"cell_type":"code","source":["################################################################################\n","######################### CHANGE BQ PROJECT NAME BELOW #########################\n","################################################################################"],"metadata":{"id":"08Cb3TQrMowt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bigquery df\n","SELECT *\n","FROM `.RBA_demo.cleaned_data`\n","ORDER BY date; #update with project name. "],"metadata":{"id":"pAvxONNfMs1m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"JnYNLNdIMsy_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.1) Define KPI column and feature set"],"metadata":{"id":"UmtXOMvHMzg0"}},{"cell_type":"code","metadata":{"id":"qxSRpjLrxIvo"},"source":["date_col = 'date' #@param {type:\"string\"}\n","df = df.drop(columns = [date_col]) # drop date column since it's not part of the feature set\n","\n","kpi_col = \"y1\" #@param {type:\"string\"}\n","y = df[kpi_col]\n","X = df[df.columns[df.columns != kpi_col]].values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lVBNE964LY2H"},"source":["## 2) Build RBA Model"]},{"cell_type":"markdown","source":["Create a linear model to measure the impact of digital media (x variables) on conversions (y variable).\n","\n","Different regularization techniques, such as Ridge or Lasso, can be implemented to adjust for highly correlated features."],"metadata":{"id":"wfMj2cgaQPoi"}},{"cell_type":"markdown","source":["### 2.1) Run the model and print evaluation metrics"],"metadata":{"id":"JLVlHK8gcfOA"}},{"cell_type":"code","source":["train_test_split = ''\n","test_size = 0.10 #@param {type:\"number\"}"],"metadata":{"id":"-wK7Ii2HpMen"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if train_test_split == 'Y':\n","  \n","  # separate data into train and test based on fraction of test size\n","  train_df = df[:round(len(df.index)*(1-test_size))]\n","  test_df = df[round(len(df.index)*(1-test_size)):]\n","\n","  # split train and test into x/y columns\n","  train_x = train_df[train_df.columns[train_df.columns != KPI_COL]].values\n","  test_x = test_df[test_df.columns[test_df.columns != KPI_COL]].values\n","\n","  train_y = train_df[KPI_COL]\n","  test_y = test_df[KPI_COL]\n","\n","  # run the model on the training data\n","  reg = Ridge().fit(train_x,train_y)\n","\n","  # eval metrics - r-squared on training data\n","  print('Training Rsquared: ' , round(reg.score(train_x,train_y),2))\n","  print('Test Rsquared: ' , round(reg.score(test_x,test_y),2))\n","\n","  # Generate predictions to calculate MAE, MSE, RMSE\n","  Y_prediction = reg.predict(test_x)\n","  print('MAE: ' , round(mean_absolute_error(test_y,Y_prediction),2))\n","  print('MSE: ', round(mean_squared_error(test_y,Y_prediction),2))\n","  print('RMSE: ',round(np.sqrt(mean_squared_error(test_y,Y_prediction)),2))\n","\n","else:\n","  # run the model on the full dataset\n","  reg = Ridge().fit(X,y)\n","\n","  # Generate predictions to calculate residuals\n","  Y_prediction = reg.predict(X)\n","\n","  # eval metrics - r-squared on full dataset\n","  print('R-squared: ',round(reg.score(X,y),2))"],"metadata":{"id":"B04cpU6VnYMj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.2) Cross-validation"],"metadata":{"id":"nEHQ4hSSKRtn"}},{"cell_type":"code","source":["cross_val = '' #@param {type:\"string\"}"],"metadata":{"id":"eQahMHO0pweX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if cross_val == 'Y':\n","  tscv = TimeSeriesSplit(n_splits = 5)\n","  \n","  # get number of splits\n","  print('Number of splits: ',tscv.get_n_splits())\n","\n","  #### Compute average test sets score: ####\n","  scores = []\n","\n","  for train_index, test_index in tscv.split(df):\n","    train_x = df[:len(train_index)].drop(columns = [KPI_COL])\n","    train_y = df.y1[:len(train_index)]\n","\n","    test_x = df[len(train_index):len(train_index)+len(test_index)].drop(columns = [KPI_COL])\n","    test_y = df.y1[len(train_index):len(train_index)+len(test_index)]\n","    \n","    cv_model = Ridge()\n","    cv_model.fit(train_x,train_y)\n","\n","    preds = cv_model.predict(test_x)\n","\n","    # r-squared for the current fold only    \n","    r2score = cv_model.score(test_x,test_y)\n","    scores.append(round(r2score,2))\n","    print('Score: ', scores)\n","    cv_score = np.mean(scores)\n","    print('CV Score: ',round(cv_score,2))"],"metadata":{"id":"OTrevQVwKTXl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lFS3Fk1BObgM"},"source":["## 3) Calculate contribution of each digital tactic"]},{"cell_type":"markdown","source":["Shap values are a method for interpreting how each feature impacts a model, both locally and globally.\n","\n","More info can be found [here](https://shap.readthedocs.io/en/latest/index.html)"],"metadata":{"id":"uSSnTlori62k"}},{"cell_type":"code","source":["## Fit the explainer\n","explainer = shap.Explainer(reg.predict,X)\n","\n","## Calculate the shap values\n","shap_values = explainer(X)"],"metadata":{"id":"CtEysb4ujUe4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## shap values\n","shap.plots.bar(shap_values,max_display = len(df[df.columns[df.columns != KPI_COL]].columns))"],"metadata":{"id":"8zDIw8w-ikUM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vals= np.abs(shap_values.values).mean(axis = 0)\n","\n","feature_importance = pd.DataFrame(list(zip(df[df.columns[df.columns != KPI_COL]].columns, vals)), columns=['col_name','feature_importance_vals'])\n","feature_importance.sort_values(by=['feature_importance_vals'], ascending=False,inplace=True)\n","feature_importance"],"metadata":{"id":"sAWCB9C_krvE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# rescale the shap values to result in a scale rleative to total r-squared\n","\n","sum_feature_imp = feature_importance.feature_importance_vals.sum()\n","scale_factor = reg.score(X,y)\n","\n","feature_importance['attribution'] = feature_importance.feature_importance_vals / (sum_feature_imp / scale_factor)\n","feature_importance"],"metadata":{"id":"KavdICbtlhub"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["round(feature_importance.attribution.sum(),2)"],"metadata":{"id":"358bZDc0qVr_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ONUcKmxtCB6u"},"source":["## 4) Validate Linear Regression Model Assumptions"]},{"cell_type":"markdown","source":["### 4.1) Generate model residuals"],"metadata":{"id":"zQVGY1MeWuJA"}},{"cell_type":"code","source":["residuals = Y_prediction - y"],"metadata":{"id":"gi8LvA-nORez"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"33adShh4CwUP"},"source":["###4.2) Linearity"]},{"cell_type":"code","metadata":{"id":"p8PmoZ2bC14r"},"source":["'''\n","Visually inspect linearity between target variable (y1) and predictions\n","'''\n","plt.plot(Y_prediction,y,'o',alpha=0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cLBcLEXTC3yV"},"source":["### 4.3) Normality of Errors"]},{"cell_type":"code","source":["'''\n","Visually inspect the residuals to confirm normality\n","'''"],"metadata":{"id":"ZEl7n-nyW6tc"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_NjzxktOC_H_"},"source":["fig = sm.qqplot(residuals)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6PSlC66HDFbf"},"source":["sns.kdeplot(residuals, label = '', shade = True)\n","plt.xlabel('Model Residuals'); plt.ylabel('Density'); plt.title('Distribution of Residuals');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ko6ZzCPpDw3Y"},"source":["###4.4) Homoscedasticity\n"]},{"cell_type":"code","metadata":{"id":"NDCWmRTuEPcf"},"source":["'''\n","Visually inspect residuals to confirm constant variance\n","'''\n","plt.plot(residuals,'o',alpha=0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###4.5) Residual Autocorrelation Check"],"metadata":{"id":"Ce32ywU5R-KD"}},{"cell_type":"code","source":["'''\n","The Durbin Watson test is a statistical test for detecting autocorrelation of the \n","model residuals\n","'''\n","\n","dw = durbin_watson(residuals)\n","print('Durbin-Watson',dw)"],"metadata":{"id":"pFzrZDp3QgLB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if dw < 1.5:\n","        print('Positive autocorrelation', '\\n')\n","elif dw > 2.5:\n","        print('Negative autocorrelation', '\\n')\n","else:\n","        print('Little to no autocorrelation', '\\n')\n"],"metadata":{"id":"J_PgDerjQgis"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5) Export Final Results"],"metadata":{"id":"M0OJzs-gZ1GA"}},{"cell_type":"code","source":["final_results_df = feature_importance[['col_name','attribution']]\n","final_results_df.to_csv('rba_final_output.csv', encoding = 'utf-8-sig') \n","files.download('rba_final_output.csv')"],"metadata":{"id":"QootIs97Z3gh"},"execution_count":null,"outputs":[]}]}